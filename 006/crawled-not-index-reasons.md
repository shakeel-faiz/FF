The **"Crawled - currently not indexed"** status typically means that Googlebot has crawled the page, but it hasn't been indexed yet. There are several reasons why this might happen:

1. **Low-Quality Content**: Google may not index the page if it determines that the content is of low quality or doesn't offer enough value. Pages with thin or duplicate content, or those that don’t add much new information, may not be indexed.

2. **Duplicate Content**: If the page has similar content to other pages already indexed, Google might choose not to index it. If there is a canonical URL pointing to another page, this can also prevent indexing.

3. **Technical Issues**: Slow loading speeds, JavaScript issues, or other technical errors could prevent Google from properly indexing the page. If a page takes too long to load or has a broken script, Google may not index it.

4. **Lack of Internal Linking**: If the page is not well linked internally within the site, Googlebot may not discover or index it properly. Pages with few or no links pointing to them can be seen as less important.

5. **Manual Action or Penalty**: If the page has been penalized (due to spammy content, excessive ads, or violating Google's guidelines), Google might refuse to index it.

6. **No Index Tags or Robots.txt**: Ensure that the page doesn’t have a "noindex" tag or is not being blocked by the robots.txt file.

7. **Low Crawl Budget**: For large websites, Google might prioritize crawling more important pages. If the crawl budget is low, some pages may not get indexed.

8. **Indexing Queue**: Sometimes, Google may discover the page but hasn't indexed it yet due to delays in the indexing process.

### Steps to Fix:
1. **Improve Content Quality**: Ensure that the content is unique, relevant, and valuable. Google tends to index pages with high-quality, useful content.
2. **Fix Technical Issues**: Check for slow loading times, JavaScript errors, or broken links that could hinder indexing.
3. **Increase Internal Linking**: Ensure the page is linked from other pages on your website. This can help Googlebot find and index the page.
4. **Submit a Sitemap**: If you haven't already, submitting a sitemap via Google Search Console ensures Google knows about all the pages you want to index.
5. **Check for Noindex Tags**: Verify that the pages you want indexed don’t have a "noindex" directive in the meta tags or are blocked in the robots.txt file.

By addressing these factors, you can improve the chances of Google indexing your crawled pages.
